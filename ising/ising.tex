\documentclass[letterpaper,twocolumn,amsmath,amssymb,pre,aps,10pt]{revtex4-1}
\usepackage{graphicx} % Include figure files
\usepackage{color}
\usepackage{nicefrac} % Include for inline fractions

\usepackage{xargs}                      % Use more than one optional parameter in a new commands
\usepackage[pdftex,dvipsnames]{xcolor}  % Coloured text etc.
\usepackage[colorinlistoftodos,prependcaption,textsize=normalsize]{todonotes}
\usepackage{mdframed}
\usepackage{braket}

% define colors for comments
\definecolor{dark-gray}{gray}{0.10}
\definecolor{light-gray}{gray}{0.70}

\newcommand{\red}[1]{{\bf \color{red} #1}}
\newcommand{\green}[1]{{\bf \color{green} #1}}
\newcommand{\blue}[1]{{\bf \color{blue} #1}}
\newcommand{\cyan}[1]{{\bf \color{cyan} #1}}

\newcommand{\davidsays}[1]{{\color{red} [\green{David:} \emph{#1}]}}
\newcommand{\jpsays}[1]{{\color{red} [\blue{Jordan:} \emph{#1}]}}
\newcommandx{\jpcom}[2][1=inline]{\todo[linecolor=gray,backgroundcolor=light-gray,bordercolor=dark-gray,#1]{\textbf{Jordan says:} #2} }
\begin{document}

\title{Flat-histogram method comparison on 2D Ising Model
}

\author{Jordan K. Pommerenck} \author{David Roundy}
\affiliation{Department of Physics, Oregon State University,
  Corvallis, OR 97331}

\begin{abstract}
We examine the convergence of the stochastic approximation with a dynamic
update factor (SAD) algorithm applied to the 2D Ising model. Comparison with
stochastic approximation Monte Carlo (SAMC) and Wang-Landau (WL) methods show that SAD performs robustly and without user input knowledge of an energy range. We also compare SAD with ``production'' run WL with fixed weights which is the first of its kind recorded. Since SAD is more powerful in the common case in which the range of energies is not known in advance, the 2D Ising model presents a unique challenge since the energy range is readily known and easily discovered by WL methods.
\end{abstract}

\maketitle

\section{Introduction}
Flat-histogram Monte Carlo simulation algorithms calculate the thermodynamic
properties of various systems over a range of temperatures.  The first histogram
method used a single canonical Monte Carlo simulation to predict properties for
nearby temperatures~\cite{ferrenberg1988new}. While the method effectively
samples a narrow energy range, it proves computationally inefficient at sampling large energy ranges.

Multicanonical methods, introduced by Berg and Neuhaus, enabled flat-histogram
sampling which improved the exploration of configurational space and allowed the
simulation to overcome free-energy barriers~\cite{berg1991multicanonical, berg1992multicanonical}.
These works led to increase in the development of a variety of ``flat'' (or ``broad'') histogram
methods~\cite{penna1996broad, penna1998broad, swendsen1999transition,
wang2001determining, wang2001efficient} which could explore a wider range
of energies.  In addition to obtaining thermodynamic information for the entire
energy range for a single simulation, these approaches cannot be easily trapped
in a local energy minimum like a canonical simulation.


Wang and Landau introduced one of the most widely used flat-histogram
Monte Carlo algorithms that determined the density of states (DOS) for
a statistical system~\cite{wang2001determining,wang2001efficient}. For all of
its power, the method unfortunately requires \emph{a priori.} knowledge of several
user-defined parameters. Thus, for any given system under study, the user needs
to determine the ideal parameters in order to apply the method. The Wang-Landau
algorithm is also known to violate detailed balance (although only for brief
time intervals)~\cite{yan2003fast, shell2002generalization}. With the violation
of detailed balance, convergence of the algorithm is not guaranteed.

Because of the uncertainty of convergence for WL, many studies have been undertaken
to understand how the modification (or update) factor $\gamma$ impacts the
convergence~\cite{zhou2005understanding,lee2006convergence,
belardinelli2007wang}. Belardinelli and Pereyra showed that an update factor that decreases faster than $1/t$ leads to nonconvergence~\cite{belardinelli2007wang, belardinelli2008analysis, zhou2008optimal}, where $t$ corresponds to the number of moves. Schneider \emph{et al.} outline minor refinements algorithm including scaling the update factor with the number of energy bins~\cite{schneider2017convergence}.
These studies led to the
formation of the $1/t$-WL algorithm and also sparked some debate as to whether
the entire simulation should be split into multiple parts, called ``production run" WL, in order to preserve ergodicity and
detailed balance~\cite{jayasri2005wang, mukhopadhyay2008monte}.

Liang independently considered whether WL could be treated as a special case of
stochastic approximation whose convergence could be mathematically
proven~\cite{liang2006theory, liang2007stochastic}. In 2007, Liang et
al.~\cite{liang2007stochastic} argued that WL can be considered a form of
stochastic approximation Monte Carlo (SAMC). Unlike WL, SAMC can guarantee
convergence (if certain conditions are met). Despite the added benefit of
guaranteed convergence, the method still has a system specific user-defined
variable. Such variables often create difficulty when applying Monte Carlo
methods across arbitrary systems.

Kim \emph{et al.} introduced Statistical Temperature Monte Carlo (STMC) and the
related Statistical Temperature Molecular Dynamics (STMD), an adaption
of the WL method that approximates the entropy as a piecewise linear function,
which improves convergence for systems with a continuously varying
energy~\cite{kim2006statistical, kim2007statistical}. STMC applied to WL
requires a temperature range be specified rather than an energy range.  Kim
\emph{et al.} extended this work as Replica Exchange Statistical Temperature
Monte Carlo (RESTMC), which uses replica exchange of multiple overlapping STMC
simulations to improve convergence~\cite{kim2009replica}. Recently,
Junghans \emph{et al.} demonstrated a close connection between
metadynamics, which was introduced by Laio and
Parinello~\cite{laio2002escaping}, and WL-based Monte Carlo methods, with STMD
forging the connection~\cite{junghans2014molecular}.

The SAD (stochastic approximation with a
dynamic $\gamma$) method outlined by Pommerenck
et.al~\cite{pommerenck2020stochastic} is a special version of the SAMC algorithm
that dynamically chooses the modification factor rather than relying on system
dependent parameters. SAD shares the same convergence properties with SAMC while
replacing un-physical user-defined parameters with the algorithms dynamic
choice.

In this work, we apply the family of weight-based flat-histogram Monte
Carlo methods (WL, 1/t-WL, SAMC, SAD) to the 2D Ising model.

\section{Ising Model}
The 2D Ising spin-lattice system is widely used as a testbed when
benchmarking or comparing Monte Carlo
methods~\cite{ferdinand1969bounded, wang1999transition, trebst2004optimizing, barash2019estimating}. The 2nd order
phase transition behavior and the ability to directly calculate the
exact solution for finite lattices~\cite{beale1996exact, haggkvist2004computation} make the
system sufficiently interesting for such theoretical comparisons. It is
also important to note that direct comparison of the other methods can
be made with WL as its original implementation was done on this
system~\cite{wang2001determining,wang2001efficient}.
We test the convergence of several flat-histogram methods
on the periodic 2D square lattice ferromagnetic Ising model with nearest
neighbor interactions~\cite{landau2004new}.
\begin{align}
\mathcal{H} = -\sum_{\braket{i,j}} \sigma_i \sigma_j - h \sum_i s_i
\end{align}
The $N\times N$ spin system can take on values of $\sigma_i = \pm 1$
for up or down spins respectively. In the absence of a magnetic field ($h =
0$), We can write the Hamiltonian as follows~\cite{onsager1944crystal,
kaufman1949crystal}:
\begin{align}
\mathcal{H} = -\sum_{\braket{i,j}} \sigma_i \sigma_j
\end{align}
where the sum is over nearest neighbor spin sites. Beale showed that for finite
lattices the Density of States could directly be calculated from the partition
function~\cite{beale1996exact}
\begin{align}
Z = \sum_E g(E) e^{-{\beta E}}
\end{align}
% where $g(E)$ is the multiplicity of the system which is proportional to
% $D(E)$. We can estimate the average deviation from the exact solution
% using the relation~\cite{schneider2017convergence, shakirov2018convergence,
% barash2017control}:
% \begin{align}
% \braket{\epsilon(t)}_E = \frac{1}{N_E - 1} \sum_E \left( \frac{S(E,t) - S_{\text{Beale}(E)}}{S_{\text{Beale}(E)}} \right)
% \end{align}
where $g(E)$ is the multiplicity of the system which is proportional to
$D(E)$. We can estimate the maximum deviation in the canonical specific heat capacity $c_V$ from the exact solution~\cite{schneider2017convergence, shakirov2018convergence,
barash2017control,barash2017gpu}:
\begin{align}
\braket{\epsilon(t)}_E = \left|\max_E \left(c_V(E,S,T,t) - c_V(E,S,T,t)_{\text{Beale}}\right)\right|
\end{align}
% As per the implementation by Wang and
% Landau~\cite{wang2001determining}, the total number of available energy
% states are $N-1$.
Computing the specific heat capacity $c_V$ presents a difficult challenge for
any Monte Carlo method due to fluctuations in the derivative of the internal energy.  Methods that accurately compute $c_V$ also by extension accurately compute the internal energy.

\section{Flat-histogram methods}\label{sec:histogram}
Flat-histogram methods determine the density of states $D(E)$ over a broad range
of energies by simulating each energy with equivalent accuracy. Flat-histogram
Monte Carlo methods propose randomly chosen ``moves'' which change the state of
the system and must satisfy detailed balance.  Each algorithm differs in how it
determines the probability of accepting a move and in what additional statistics
must be collected in order decide on that probability.

We describe several closely related flat-histogram methods which each rely on a
weight function $w(E)$ to determine $D(E)$.  For these algorithms, the
probability of accepting a move is given by
\begin{equation}
	\mathcal{P}(E_\text{old} \rightarrow E_\text{new})
	= \min\left[1,\frac{w(E_\text{old})}{w(E_\text{new})}\right]
\end{equation}
which biases the simulation in favor of energies with low weights. The result of
weights $w(E)$ that are proportional to $D(E)$ is an entirely flat-histogram. We
can relate the entropy to the weights in the microcanonical ensemble, since the
entropy is defined as $S(E) \equiv k_B\ln(D(E)) \approx \ln w(E)$.

Flat-histogram methods employ a random walk in energy space to estimate $D(E)$.  Each method operates by continuously updating the weights at each
step of the simulation
\begin{equation}
	\ln{w_{t+1}(E)}=\ln{w_{t}(E)}
	+\gamma_t
\end{equation}
where $t$ is number of the current move, $\gamma(t)$ is a move-dependent update
factor, and $E$ is the current energy.  This update causes the random walk to
avoid frequent sampling of the same energies, leading to a rapid exploration
of energy space. Flat-histogram methods differ primarily in how they schedule
the decrease of $\gamma_t$.

The Wang-Landau algorithm~\cite{wang2001efficient,wang2001determining,
landau2014guide} explores energy space by setting $\gamma_{t=0}^{\text{WL}}=1$,and then decreases $\gamma^{\text{WL}}$ in prescribed stages. An energy range of
interest must be specified~\cite{wang2001efficient, schulz2003avoiding,yan2003fast}, which often requires multiple simulations if unknown.

The number (``counts'') of moves ending at each energy are stored in a
histogram.  For a sufficiently flat energy histogram (typically user-specified to be 0.8), $\gamma^{\text{WL}}$ is decreased by a specified factor of $\frac12$ and the histogram is reset to zero. The entire process is repeated until $\gamma^{\text{WL}}$ reaches a desired cutoff.

The $1/t$-WL algorithm ensures convergence by preventing the $\gamma_t$ factor
from dropping below $N_S/t$~\cite{belardinelli2008analysis,
schneider2017convergence}. The method follows the standard WL algorithm with two
modifications.  Firstly, when each energy state has been visited once, the histogram is considered flat and $\gamma_t$ is
decreased by a factor of two. Secondly, when
$\gamma^{\text{WL}} < N_S/t$ at time $t_0$, the update factor becomes
$\gamma_t = N_S/t$ for the remainder of the simulation:
\begin{align}
  \gamma_t^{1/t\text{-WL}} = \begin{cases}
     \gamma^{\text{WL}}_t & \gamma^{\text{WL}}_t > \frac{N_S}{t} \\
     \frac{N_S}{t} & t \ge t_0
 \end{cases}
\end{align}
where $t$ is the number of moves, $\gamma^{\text{WL}}_t$ is the Wang-Landau update factor
at move $t$, and $N_S$ is the number of energy bins.

The WL method can alternatively be implemented as part of a production run which aids in
equilibration~\cite{gross2018massively}. WL is used to generate the weights
resulting in a flat-histogram~\cite{janke2017generalized}. Once a user-defined
minimum $\gamma^{\text{WL}}_t$ is reached, the simulation switches to a final production run
with fixed weights. WL implemented in this way can ensure ergodicity and
detailed balance; however, the convergence of simulation is still impacted by
the choice of the minimum $\gamma^{\min}_t$.

Another weight-based flat-histogram method is
the stochastic approximation Monte Carlo (SAMC) algorithm. SAMC has a simple
schedule by which the update factor $\gamma^{\text{SA}}_t$ is continuously
decreased~\cite{liang2007stochastic, werlich2015stochastic,
schneider2017convergence}.  The update factor is defined in the
original implementation~\cite{liang2007stochastic} in terms of an
arbitrary tunable parameter $t_0$,
\begin{align}
\gamma_{t}^{\text{SA}} =\frac{t_0}{\max(t_0,t)}
\end{align}
where as above $t$ is the number of moves that have been attempted.

The implementation of SAMC is extremely simplistic.
In addition, Liang has proven that the weights converge to the true
density of states~\cite{liang2006theory, liang2007stochastic,
liang2009improving} provided the update factor satisfies
\begin{align}
\sum_{t=1}^\infty \gamma_{t} = \infty \quad\textrm{and}\quad
\sum_{t=1}^\infty \gamma_{t}^\zeta < \infty
\end{align}
where $\zeta > 1$.  Unlike WL methods, the energy range need not be
known \emph{a priori.} and the convergence time depends only on the choice of
parameter $t_0$.
Unfortunately, $t_0$ can be difficult to chose in advance
for arbitrary systems.
Liang \emph{et al.} give a rule of thumb in
which $t_0$ is chosen in the range from $2N_S$ to $100N_S$ where $N_S$
is the number of energy bins~\cite{liang2007stochastic}.  Schneider
\emph{et al.} found and we confirm that for the Ising model this heuristic is helpful for small spin systems, but that larger systems require an even higher
$t_0$ value~\cite{schneider2017convergence}.

Pommerenck et al. propose a refinement~\cite{pommerenck2020stochastic} to SAMC
where the update factor is determined dynamically rather than by the user.
stochastic approximation with a dynamic $\gamma$ (SAD) requires the user to
provide the lowest temperature of interest $T_{\min}$. This is analogous to WL
requiring \emph{a priori.} an energy range of interest; however, this is almost always easier to
identify and is more physical than the SAMC parameter $t_0$. The update factor
can be written in terms of the current estimates for the highest $E_H$ and
lowest $E_L$ energies of interest and the last time that an energy in the range
of interest is encountered $t_L$.
\begin{align}
  \gamma_{t}^{\text{SAD}} =
     \frac{
       \frac{E_{H}-E_{L}}{T_{\text{min}}} + \frac{t}{t_L}
     }{
       \frac{E_{H}-E_{L}}{T_{\text{min}}} + \frac{t}{N_S}\frac{t}{t_L}
     }
\end{align}
SAD only explores the energy range of interest as specified by the minimum
temperature of interest $T_{\min} < T < \infty$. During the simulation the two
energies $E_H$ and $E_L$, are refined such that the range of energies are conservatively
estimated. The weights are calculated for each energy region according to the original
prescription.
\begin{enumerate}
\item {$E < E_L$:} $w(E>E_H) = w(E_H)$
\item {$E_L < E < E_H$:} moves are handled the same as other weight-based
methods that are mentioned
\item {$E > E_H$:} $w(E<E_L) = w(E_L)e^{-\frac{E_L-E}{T_{\min}}}$
\end{enumerate}
Each time the simulation changes the value of $E_H$ or $E_L$, the weights
within the new portion of the interesting energy range are updated.

\section{Results}
We tested the algorithms on two different system sizes of the 2D Ising model.  The first is a smaller
simulation with a lattice size of $N = 32 \times 32$ and the second has a lattice size of $N = 128 \times 128$. The SAD method explores the energy
space of each system using a minimum reduced temperature of $T_{\text{min}} = 1$. All simulations lead to the minimum important energy $E_{\min}$
and maximum entropy energy $E_{\max}$ being calculated (with the exception of
the WL methods where both of these parameters are needed \emph{a priori.}).

\begin{figure}
\includegraphics[width=\columnwidth]{gamma-n32.pdf}
  \caption{
  The update factor $\gamma_t$ versus the iteration number for the $N=32 \times 32$
  system.}
  \label{fig:N32-gamma}
\end{figure}

\begin{figure}
  \includegraphics[width=\columnwidth]{N32-Cv.pdf}
    \caption{
    The specific heat capacity versus the reciprocal temperature $\beta$ for the $N=32 \times 32$ system for each histogram method.}
    \label{fig:N32-cv}
  \end{figure}

\begin{figure}
  \includegraphics[width=\columnwidth]{N32-Cv-error-default.pdf}
  \caption{The maximum error in the specific heat capacity for each method for the $N=32 \times 32$ and $T_{\min} = 1$ as a function of number of iterations run.  The maximum error is averaged over 8 independent simulations, and the best and worst simulations for each method are shown as a semi-transparent shaded area.}
  \label{fig:N32-cv-error}
\end{figure}

% \begin{figure}
% \includegraphics[width=\columnwidth]{N32-entropy-error-default.pdf}
%   \caption{
%   The average entropy error for each MC method for $N=32 \times 32$,
%                $\delta_0 = 0.05\sigma$, and $T_{\min} = 1$
%                as a function of number of iterations run.  The error is
%                averaged over 8 independent simulations, and the best
%                and worst simulations for each method are shown as a
%                semi-transparent shaded area.}\label{fig:n32}
% \end{figure}

\subsection{The 32 $\times$ 32 Ising model}
Fig.~\ref{fig:N32-gamma} shows the update factor $\gamma_t$ for each of the flat-histogram methods. All of the update factors initially start at $\gamma_{t=0} = 1$. SAD dynamically updates $\gamma_t$ throughout the simulation. After about $10^{10}$ moves, $\gamma^{\text{SAD}}_t$ proceeds as $1/t$. Both WL and ``production'' WL update factors $\gamma^{\text{WL}}_t$ are shown. The production WL begins after $\gamma^{\text{WL}}_t$ has reached $10^{-4}$. The update factor for $1/t$-WL decreases similarly to WL before finding all the energy states and switching to $1/t$. All of the SAMC update factors equal 1 until the number of moves is equal to $t_0$ at which point they decrease as $1/t$.

Fig.~\ref{fig:N32-cv-error} shows the maximum error in the heat capacity as a function of time for
this system. The solid/dashed lines
represent the average of the maximum value of the error in the specific heat capacity $c_V$ averaged
over eight simulations using different random number seeds. The range of maximum
errors for each simulation is shown as a shaded region. By
the time $10^8$ moves have been made all but the WL simulation have begun to
converge as $1/\sqrt{t}$. We then see the WL error saturate around $10^9$ moves.

\begin{figure}
\includegraphics[width=\columnwidth]{gamma-n128.pdf}
  \caption{
  The update factor $\gamma_t$ versus the iteration number for the $N=128 \times 128$
  system.}
  \label{fig:N128-gamma}
\end{figure}

\begin{figure}
  \includegraphics[width=\columnwidth]{N128-Cv-error-default.pdf}
  \caption{The maximum error in the specific heat capacity for each method for the $N=128 \times 128$ and $T_{\min} = 1$ as a function of number of iterations run.  The maximum error is averaged over 8 independent simulations, and the best and worst simulations for each method are shown as a semi-transparent shaded area.}
  \label{fig:N128-cv-error}
\end{figure}

% \begin{figure}
% \includegraphics[width=\columnwidth]{N128-entropy-error-default.pdf}
%   \caption{
%   The average entropy error for each MC method for $N=128 \times 128$,
%                $\delta_0 = 0.05\sigma$, and $T_{\min} = 1$
%                as a function of number of iterations run.  The error is
%                averaged over 8 independent simulations, and the best
%                and worst simulations for each method are shown as a
%                semi-transparent shaded ar.}\label{fig:n128}
% \end{figure}

\subsection{128 $\times$ 128 Ising system}
Fig.~\ref{fig:N128-gamma} shows the update factor $\gamma_t$ for each of the flat-histogram methods. All of the update factors initially start at $\gamma_{t=0} = 1$. SAD dynamically updates $\gamma_t$ throughout the simulation. After about $10^{13}$ moves, $\gamma^{\text{SAD}}_t$ proceeds as $1/t$. Both WL and ``production'' WL update factors $\gamma^{\text{WL}}_t$ are shown. The production WL begins after $\gamma^{\text{WL}}_t$ has reached $10^{-4}$ and $10^{-6}$. The update factor for $1/t$-WL decreases similarly to WL before finding all the energy states and switching to $1/t$. All of the SAMC update factors equal 1 until the number of moves is equal to $t_0$ at which point they decrease as $1/t$.

Fig.~\ref{fig:N128-cv-error} shows the maximum error in the heat capacity as a function of time for
this system. The solid/dashed lines
represent the average of the maximum value of the error in the specific heat capacity $c_V$ averaged
over eight simulations using different random number seeds. The range of maximum
errors for each simulation is shown as a shaded region. By
the time $10^{13}$ moves have been made all but the WL simulation have begun to
converge as $1/\sqrt{t}$. We then see the WL error saturate around $10^{12}$ moves.

\section{Conclusion}
The method performs as well as 1/t-WL and SAD.  Unfortunately, the addition of another tunable parameter $\gamma_{t}^{\min}$ makes the method somewhat more difficult to implement in practice.

We find that both SAD, 1/t-WL, and production WL (provided an ideal minimum update factor before beginning the production run) demonstrate excellent and robust convergence.
They all converge more rapidly than SAMC, and unlike WL do not suffer from
error saturation. We find that for larger systems SAD reduces the updated factor
more slowly (and conservatively) than 1/t-WL and production WL. This means that SAD will take
proportionately more moves to converge to the same value as 1/t-WL as system
size is increased. SAD requires the user to specify a temperature range of
interest rather than an energy range of interest as the WL methods do. The 2D Ising model is a system where the energy range is known \emph{a priori.}, which makes a comparison between WL methods and SAD (which requires a minimum temperature) more biased towards WL methods. For the majority of cases in which the energy range of the system is not known and where a range of desired temperatures is known, this will make the SAD method
considerably more convenient. This work also visually demonstrates that ``production'' WL performs extremely well and is preferable to WL for ensuring both ergodicity and detailed balance.

\section{Acknowledgments}

We thank Klas Markstr\"{o}m for discussions regarding the exact computation of the partition function for the 2D Ising model. We also wish to thank Johannes Zierenberg for helpful discussions regarding WL production run simulations and
Martin Weigel for discussions regarding entropic population annealing.

\bibliography{ising} % Produces the bibliography via BibTeX.

\end{document}
